{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c071ef01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             model    metric    mean     std   min   max  \\\n",
      "0                    claude-opus-4    Manner  0.7556  0.1269  0.28  0.88   \n",
      "1                    claude-opus-4   Quality  0.5889  0.1289  0.38  0.78   \n",
      "2                    claude-opus-4  Quantity  0.5600  0.1240  0.42  0.75   \n",
      "3                    claude-opus-4  Relation  0.7317  0.1768  0.15  0.85   \n",
      "4                  claude-sonnet-4    Manner  0.7644  0.0892  0.45  0.82   \n",
      "5                  claude-sonnet-4   Quality  0.5944  0.1403  0.20  0.73   \n",
      "6                  claude-sonnet-4  Quantity  0.5356  0.1354  0.25  0.67   \n",
      "7                  claude-sonnet-4  Relation  0.7900  0.0427  0.71  0.85   \n",
      "8   gemini-2.5-flash-preview-05-20    Manner  0.8306  0.0389  0.75  0.90   \n",
      "9   gemini-2.5-flash-preview-05-20   Quality  0.6194  0.0957  0.40  0.75   \n",
      "10  gemini-2.5-flash-preview-05-20  Quantity  0.5833  0.1125  0.30  0.75   \n",
      "11  gemini-2.5-flash-preview-05-20  Relation  0.8722  0.0548  0.70  0.90   \n",
      "12          gemini-2.5-pro-preview    Manner  0.8778  0.0548  0.80  0.95   \n",
      "13          gemini-2.5-pro-preview   Quality  0.5972  0.0931  0.35  0.70   \n",
      "14          gemini-2.5-pro-preview  Quantity  0.5806  0.1031  0.35  0.80   \n",
      "15          gemini-2.5-pro-preview  Relation  0.8750  0.0549  0.75  0.95   \n",
      "16                         gpt-4.1    Manner  0.8461  0.0382  0.78  0.90   \n",
      "17                         gpt-4.1   Quality  0.6544  0.0474  0.60  0.73   \n",
      "18                         gpt-4.1  Quantity  0.6172  0.0470  0.54  0.68   \n",
      "19                         gpt-4.1  Relation  0.7739  0.0407  0.70  0.85   \n",
      "\n",
      "    count  median  \n",
      "0      18   0.780  \n",
      "1      18   0.580  \n",
      "2      18   0.570  \n",
      "3      18   0.810  \n",
      "4      18   0.780  \n",
      "5      18   0.635  \n",
      "6      18   0.620  \n",
      "7      18   0.780  \n",
      "8      18   0.850  \n",
      "9      18   0.650  \n",
      "10     18   0.600  \n",
      "11     18   0.900  \n",
      "12     18   0.900  \n",
      "13     18   0.600  \n",
      "14     18   0.600  \n",
      "15     18   0.900  \n",
      "16     18   0.850  \n",
      "17     18   0.655  \n",
      "18     18   0.635  \n",
      "19     18   0.775  \n"
     ]
    }
   ],
   "source": [
    "# inspired by https://github.com/touche-webis-de/touche-code/blob/main/clef25/retrieval-augmented-debating/evaluator/sub-task-2/evaluate.py\n",
    "\n",
    "import pandas as pd\n",
    "from pydantic import BaseModel\n",
    "from typing import List\n",
    "\n",
    "\n",
    "class Evaluation(BaseModel):\n",
    "    score: float\n",
    "\n",
    "\n",
    "class TurnEvaluations(BaseModel):\n",
    "    Quantity: Evaluation\n",
    "    Quality: Evaluation\n",
    "    Relation: Evaluation\n",
    "    Manner: Evaluation\n",
    "\n",
    "\n",
    "class DebateEvaluations(BaseModel):\n",
    "    userTurnsEvaluations: List[TurnEvaluations]\n",
    "\n",
    "\n",
    "def analyze_evaluation_files_with_pydantic(file_model_mapping):\n",
    "    all_scores_data = []\n",
    "\n",
    "    for model_name, file_path in file_model_mapping.items():\n",
    "        with open(file_path, \"r\") as f:\n",
    "            for i, line in enumerate(f):\n",
    "                if not line.strip():\n",
    "                    continue\n",
    "                debate_eval_obj = DebateEvaluations.model_validate_json(line)\n",
    "\n",
    "                debate_id_for_tracking = f\"Debate_{i+1}\"\n",
    "\n",
    "                for turn_idx, turn_eval_data in enumerate(\n",
    "                    debate_eval_obj.userTurnsEvaluations\n",
    "                ):\n",
    "                    scores_in_turn = {\n",
    "                        \"Quality\": turn_eval_data.Quality.score,\n",
    "                        \"Quantity\": turn_eval_data.Quantity.score,\n",
    "                        \"Relation\": turn_eval_data.Relation.score,\n",
    "                        \"Manner\": turn_eval_data.Manner.score,\n",
    "                    }\n",
    "\n",
    "                    for metric_name, score_value in scores_in_turn.items():\n",
    "                        score = float(score_value)\n",
    "                        all_scores_data.append(\n",
    "                            {\n",
    "                                \"model\": model_name,\n",
    "                                \"debate_id\": debate_id_for_tracking,\n",
    "                                \"turn_id\": turn_idx + 1,\n",
    "                                \"metric\": metric_name,\n",
    "                                \"score\": score,\n",
    "                            }\n",
    "                        )\n",
    "\n",
    "    df = pd.DataFrame(all_scores_data)\n",
    "    return (\n",
    "        df.groupby([\"model\", \"metric\"])[\"score\"]\n",
    "        .agg([\"mean\", \"std\", \"min\", \"max\", \"count\", \"median\"])\n",
    "        .reset_index()\n",
    "        .round(4)\n",
    "    )\n",
    "\n",
    "\n",
    "def expand_path(model: str) -> str:\n",
    "    base_path = \"../evals\"\n",
    "    return f\"{base_path}/{model}.jsonl\"\n",
    "\n",
    "\n",
    "models = [\n",
    "    \"gemini-2.5-flash-preview-05-20\",\n",
    "    \"gemini-2.5-pro-preview\",\n",
    "    \"gpt-4.1\",\n",
    "    \"gpt-4o\",\n",
    "    \"claude-opus-4\",\n",
    "    \"claude-sonnet-4\",\n",
    "]\n",
    "\n",
    "file_model_mapping = {model: expand_path(model) for model in models}\n",
    "\n",
    "results = analyze_evaluation_files_with_pydantic(file_model_mapping)\n",
    "if results is not None:\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4d116d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f96edc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
